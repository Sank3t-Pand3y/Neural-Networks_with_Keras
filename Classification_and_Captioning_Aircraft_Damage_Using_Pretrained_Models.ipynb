{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+6PAYew/FWAEmfUteGaDV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sank3t-Pand3y/Neural-Networks_with_Keras/blob/main/Classification_and_Captioning_Aircraft_Damage_Using_Pretrained_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Project Overview**\n",
        "\n",
        "Aircraft damage detection is essential for maintaining the safety and longevity of aircraft. Traditional manual inspection methods are time-consuming and prone to human error. This project aims to automate the classification of aircraft damage into two categories: \"dent\" and \"crack.\" For this, we will utilize feature extraction with a pre-trained VGG16 model to classify the damage from aircraft images. Additionally, we will use a pre-trained Transformer model to generate captions and summaries for the images.\n",
        "\n",
        "## **Aim of the Project**\n",
        "\n",
        "The goal of this project is to develop an automated model that accurately classifies aircraft damage from images. By the end of the project, you will have trained and evaluated a model that utilizes feature extraction from VGG16 for damage classification. This model will be applicable in real-world damage detection within the aviation industry. Furthermore, the project will showcase how we can use a Transformer-based model to caption and summarize images, providing a detailed description of the damage.\n",
        "\n",
        "## **Final Output**\n",
        "\n",
        "- A trained model capable of classifying aircraft images into \"dent\" and \"crack\" categories, enabling automated aircraft damage detection.\n",
        "- A Transformer-based model that generates captions and summaries of images\n"
      ],
      "metadata": {
        "id": "eRDu5bFHIyG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Table of Contents</h2>\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "    <p><font size=\"5\">Part 1 - Classification Problem: Classifying the defect on the aircraft as 'dent' or 'crack'</p>\n",
        "<font size=\"3\">\n",
        "        1. <a href=\"#1.1-Dataset-Preparation\">1.1 Dataset Preparation</a><br>\n",
        "        2. <a href=\"#1.2-Data-Preprocessing\">1.2 Data Preprocessing</a><br>\n",
        "        3. <a href=\"#1.3-Model-Definition\">1.3 Model Definition</a><br>\n",
        "        4. <a href=\"#1.4-Model-Training\">1.4 Model Training</a><br>\n",
        "        5. <a href=\"#1.5-Visualizing-Training-Results\">1.5 Visualizing Training Results</a><br>\n",
        "        6. <a href=\"#1.6-Model-Evaluation\">1.6 Model Evaluation</a><br>\n",
        "        7. <a href=\"#1.7-Visualizing-Predictions\">1.7 Visualizing Predictions</a><br>\n",
        "    <br>\n",
        "<p><font size=\"5\">Part 2: Image Captioning and Summarization using BLIP Pretrained Model</p>\n",
        "<font size=\"3\">\n",
        "        1. <a href=\"#2.1-Loading-BLIP-Model\">2.1 Loading BLIP Model</a><br>\n",
        "        2. <a href=\"#2.2-Generating-Captions-and-Summaries\">2.2 Generating Captions and Summaries</a><br>\n",
        "        <br>\n",
        "    \n"
      ],
      "metadata": {
        "id": "NnbB7GwPI_Cr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HiEQ-UkKIyj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 :- Classification Problem. Classifying the defect on the aircraft as \"Dent\" or \"Crack\"."
      ],
      "metadata": {
        "id": "bATAIx9VJNOb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-BQt5p-JXTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Dataset_Preparation."
      ],
      "metadata": {
        "id": "85vpo51_JZ-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives\n",
        "\n",
        "After you complete the project, you will be able to:\n",
        "\n",
        "- Use the VGG16 model for image classification.\n",
        "- Prepare and preprocess image data for a machine learning task.\n",
        "- Evaluate the modelâ€™s performance using appropriate metrics.\n",
        "- Visualize model predictions on test data.\n",
        "- Use a custom Keras layer.\n",
        "\n",
        "\n",
        " ### Task List\n",
        "To achieve the above objectives, you will complete the following tasks:\n",
        "\n",
        "- Task 1: Create a `valid_generator` using the `valid_datagen` object\n",
        "- Task 2: Create a `test_generator` using the `test_datagen` object\n",
        "- Task 3: Load the VGG16 model\n",
        "- Task 4: Compile the model\n",
        "- Task 5: Train the model\n",
        "- Task 6: Plot accuracy curves for training and validation sets\n",
        "- Task 7: Visualizing the results\n",
        "- Task 8: Implement a Helper Function to Use the Custom Keras Layer\n",
        "- Task 9: Generate a caption for an image using the using BLIP pretrained model\n",
        "- Task 10: Generate a summary of an image using BLIP pretrained model\n",
        "\n",
        "**Note**:.<br>\n",
        "1. For each task, copy and save the code or output as mentioned in the task for final grading.<br>\n",
        "2. Download the file after completion of the final project.The file should have both code and output.This will be used for final grading.\n"
      ],
      "metadata": {
        "id": "Mcos0CkQJfUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "C5ogLz0AJdCJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "metadata": {
        "id": "OW0sW7qvJktw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.applications import VGG16\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "import random"
      ],
      "metadata": {
        "id": "ASiQX9-6JwN2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Set Seed for Reproducibility\n",
        "seed_value = 42\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)"
      ],
      "metadata": {
        "id": "Kx14AJCRKOoM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Data Preparation."
      ],
      "metadata": {
        "id": "-vXKk65lKcqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Set the batch size, epochs\n",
        "batch_size = 32\n",
        "n_epochs = 5\n",
        "img_rows, img_cols = 224, 224\n",
        "input_shape = (img_rows, img_cols, 3)"
      ],
      "metadata": {
        "id": "yngnzFC0KZBB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the Dataset:\n",
        "Unzip the dataset to the current directory, creating directories for training, testing, and validation splits.\n"
      ],
      "metadata": {
        "id": "ajjPPWqMKued"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import urllib.request\n",
        "import oauth2client\n",
        "import shutil\n",
        "\n",
        "## URL of the tar file\n",
        "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ZjXM4RKxlBK9__ZjHBLl5A/aircraft-damage-dataset-v1.tar\"\n",
        "\n",
        "## Define the path to save the file.\n",
        "tar_filename = \"aircraft-damage-dataset-v1.tar\"\n",
        "extracted_folder = \"aircraft-damage-dataset-v1\"  ## Folder where contents will be extracted\n",
        "\n",
        "## Download the file\n",
        "urllib.request.urlretrieve(url, tar_filename)\n",
        "print(f\"Download {tar_filename}. Extraction will begin now.\")\n",
        "\n",
        "## Check if the folder already exists\n",
        "if os.path.exists(extracted_folder):\n",
        "    print(f\"The folder '{extracted_folder}' already exists. Removing the existing folder.\")\n",
        "\n",
        "    # Remove the existing folder to avoid overwriting or duplication\n",
        "    shutil.rmtree(extracted_folder)\n",
        "    print(f\"Removed the existing folder: {extracted_folder}\")\n",
        "\n",
        "# Extract the contents of the tar file\n",
        "with tarfile.open(tar_filename, \"r\") as tar_ref:\n",
        "    tar_ref.extractall()  # This will extract to the current directory\n",
        "    print(f\"Extracted {tar_filename} successfully.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGM9SgH_KqFH",
        "outputId": "1a2c96d8-16d9-4625-e52a-670520a9de18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download aircraft-damage-dataset-v1.tar. Extraction will begin now.\n",
            "Extracted aircraft-damage-dataset-v1.tar successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IFOpFjASLmji"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}