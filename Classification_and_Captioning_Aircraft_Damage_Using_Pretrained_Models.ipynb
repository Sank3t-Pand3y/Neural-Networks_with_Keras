{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmck4NBDzrMpkzHg8FhLNE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sank3t-Pand3y/Neural-Networks_with_Keras/blob/main/Classification_and_Captioning_Aircraft_Damage_Using_Pretrained_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Project Overview**\n",
        "\n",
        "Aircraft damage detection is essential for maintaining the safety and longevity of aircraft. Traditional manual inspection methods are time-consuming and prone to human error. This project aims to automate the classification of aircraft damage into two categories: \"dent\" and \"crack.\" For this, we will utilize feature extraction with a pre-trained VGG16 model to classify the damage from aircraft images. Additionally, we will use a pre-trained Transformer model to generate captions and summaries for the images.\n",
        "\n",
        "## **Aim of the Project**\n",
        "\n",
        "The goal of this project is to develop an automated model that accurately classifies aircraft damage from images. By the end of the project, you will have trained and evaluated a model that utilizes feature extraction from VGG16 for damage classification. This model will be applicable in real-world damage detection within the aviation industry. Furthermore, the project will showcase how we can use a Transformer-based model to caption and summarize images, providing a detailed description of the damage.\n",
        "\n",
        "## **Final Output**\n",
        "\n",
        "- A trained model capable of classifying aircraft images into \"dent\" and \"crack\" categories, enabling automated aircraft damage detection.\n",
        "- A Transformer-based model that generates captions and summaries of images\n"
      ],
      "metadata": {
        "id": "eRDu5bFHIyG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Table of Contents</h2>\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "    <p><font size=\"5\">Part 1 - Classification Problem: Classifying the defect on the aircraft as 'dent' or 'crack'</p>\n",
        "<font size=\"3\">\n",
        "        1. <a href=\"#1.1-Dataset-Preparation\">1.1 Dataset Preparation</a><br>\n",
        "        2. <a href=\"#1.2-Data-Preprocessing\">1.2 Data Preprocessing</a><br>\n",
        "        3. <a href=\"#1.3-Model-Definition\">1.3 Model Definition</a><br>\n",
        "        4. <a href=\"#1.4-Model-Training\">1.4 Model Training</a><br>\n",
        "        5. <a href=\"#1.5-Visualizing-Training-Results\">1.5 Visualizing Training Results</a><br>\n",
        "        6. <a href=\"#1.6-Model-Evaluation\">1.6 Model Evaluation</a><br>\n",
        "        7. <a href=\"#1.7-Visualizing-Predictions\">1.7 Visualizing Predictions</a><br>\n",
        "    <br>\n",
        "<p><font size=\"5\">Part 2: Image Captioning and Summarization using BLIP Pretrained Model</p>\n",
        "<font size=\"3\">\n",
        "        1. <a href=\"#2.1-Loading-BLIP-Model\">2.1 Loading BLIP Model</a><br>\n",
        "        2. <a href=\"#2.2-Generating-Captions-and-Summaries\">2.2 Generating Captions and Summaries</a><br>\n",
        "        <br>\n",
        "    \n"
      ],
      "metadata": {
        "id": "NnbB7GwPI_Cr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HiEQ-UkKIyj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 :- Classification Problem. Classifying the defect on the aircraft as \"Dent\" or \"Crack\"."
      ],
      "metadata": {
        "id": "bATAIx9VJNOb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-BQt5p-JXTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Dataset_Preparation."
      ],
      "metadata": {
        "id": "85vpo51_JZ-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives\n",
        "\n",
        "After you complete the project, you will be able to:\n",
        "\n",
        "- Use the VGG16 model for image classification.\n",
        "- Prepare and preprocess image data for a machine learning task.\n",
        "- Evaluate the model’s performance using appropriate metrics.\n",
        "- Visualize model predictions on test data.\n",
        "- Use a custom Keras layer.\n",
        "\n",
        "\n",
        " ### Task List\n",
        "To achieve the above objectives, you will complete the following tasks:\n",
        "\n",
        "- Task 1: Create a `valid_generator` using the `valid_datagen` object\n",
        "- Task 2: Create a `test_generator` using the `test_datagen` object\n",
        "- Task 3: Load the VGG16 model\n",
        "- Task 4: Compile the model\n",
        "- Task 5: Train the model\n",
        "- Task 6: Plot accuracy curves for training and validation sets\n",
        "- Task 7: Visualizing the results\n",
        "- Task 8: Implement a Helper Function to Use the Custom Keras Layer\n",
        "- Task 9: Generate a caption for an image using the using BLIP pretrained model\n",
        "- Task 10: Generate a summary of an image using BLIP pretrained model\n",
        "\n",
        "**Note**:.<br>\n",
        "1. For each task, copy and save the code or output as mentioned in the task for final grading.<br>\n",
        "2. Download the file after completion of the final project.The file should have both code and output.This will be used for final grading.\n"
      ],
      "metadata": {
        "id": "Mcos0CkQJfUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "C5ogLz0AJdCJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "metadata": {
        "id": "OW0sW7qvJktw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.applications import VGG16\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "import random"
      ],
      "metadata": {
        "id": "ASiQX9-6JwN2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Set Seed for Reproducibility\n",
        "seed_value = 42\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)"
      ],
      "metadata": {
        "id": "Kx14AJCRKOoM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Data Preparation."
      ],
      "metadata": {
        "id": "-vXKk65lKcqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Set the batch size, epochs\n",
        "batch_size = 32\n",
        "n_epochs = 5\n",
        "img_rows, img_cols = 224, 224\n",
        "input_shape = (img_rows, img_cols, 3)"
      ],
      "metadata": {
        "id": "yngnzFC0KZBB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the Dataset:\n",
        "Unzip the dataset to the current directory, creating directories for training, testing, and validation splits.\n"
      ],
      "metadata": {
        "id": "ajjPPWqMKued"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import urllib.request\n",
        "import oauth2client\n",
        "import shutil\n",
        "\n",
        "## URL of the tar file\n",
        "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ZjXM4RKxlBK9__ZjHBLl5A/aircraft-damage-dataset-v1.tar\"\n",
        "\n",
        "## Define the path to save the file.\n",
        "tar_filename = \"aircraft-damage-dataset-v1.tar\"\n",
        "extracted_folder = \"aircraft-damage-dataset-v1\"  ## Folder where contents will be extracted\n",
        "\n",
        "## Download the file\n",
        "urllib.request.urlretrieve(url, tar_filename)\n",
        "print(f\"Download {tar_filename}. Extraction will begin now.\")\n",
        "\n",
        "## Check if the folder already exists\n",
        "if os.path.exists(extracted_folder):\n",
        "    print(f\"The folder '{extracted_folder}' already exists. Removing the existing folder.\")\n",
        "\n",
        "    # Remove the existing folder to avoid overwriting or duplication\n",
        "    shutil.rmtree(extracted_folder)\n",
        "    print(f\"Removed the existing folder: {extracted_folder}\")\n",
        "\n",
        "# Extract the contents of the tar file\n",
        "with tarfile.open(tar_filename, \"r\") as tar_ref:\n",
        "    tar_ref.extractall()  # This will extract to the current directory\n",
        "    print(f\"Extracted {tar_filename} successfully.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGM9SgH_KqFH",
        "outputId": "b3c34c75-83c4-4de0-b0e9-b0842c9e2847"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download aircraft-damage-dataset-v1.tar. Extraction will begin now.\n",
            "Extracted aircraft-damage-dataset-v1.tar successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In above code, i have \"extracted_folder\" and inside that folder we have \"tar_filename\". So, we download the tar file from the \"url\" and save it to \"tar_filename\" in \"extracted_folder\" by using \"urllib.request.urlretrieve()\".\n",
        "\n",
        "After that we Check if the folder already exist or not. We removw the existing folder to avoid overwriting or duplication through \"shutil.rmtree()\"\n",
        "\n",
        "Finally, we extract the content of tar file from \"with tarfile.open()\""
      ],
      "metadata": {
        "id": "IgBZXW3eM80e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The folder structure looks as follows:\n",
        "\n",
        "```python\n",
        "aircraft_damage_dataset_v1/\n",
        "├── train/\n",
        "│   ├── dent/\n",
        "│   └── crack/\n",
        "├── valid/\n",
        "│   ├── dent/\n",
        "│   └── crack/\n",
        "└── test/\n",
        "    ├── dent/\n",
        "    └── crack/\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "De8_YmT8N8T2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Define the directories for train, test, and validation splits.\n",
        "\n",
        "extract_path = \"aircraft-damage-dataset-v1\"\n",
        "train_dir = os.path.join(extract_path, \"train\")\n",
        "test_dir = os.path.join(extract_path, \"test\")\n",
        "valid_dir = os.path.join(extract_path, \"valid\")"
      ],
      "metadata": {
        "id": "IFOpFjASLmji"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Data Preprocessing\n",
        "\n",
        "Create data generators for training, validation, and testing datasets.\n",
        "\n",
        "First,we will create ImageDataGenerators used for training, validation and testing.\n",
        "The ImageDataGenerator class is part of Keras. It is a powerful utility for real-time image data augmentation, preprocessing, and feeding data into deep learning models during training. This class is particularly useful when working with image datasets that are too large to fit into memory all at once, or when you want to augment your dataset  to improve model generalization.\n",
        "\n",
        "We will create instances of the ImageDataGenerator class. Each instance corresponds to one of the datasets: training, validation, and testing.\n"
      ],
      "metadata": {
        "id": "awQ19HtwOLrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ImageDataGenerators to preprocess the data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "u1WpFpBPOKq0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we use flow_from_directory() method to load the images from directory and generate the training dataset. The flow_from_directory() method is part of the ImageDataGenerator class in Keras, and it plays a crucial role in automating the process of loading, preprocessing, and batching images for training, validation, and testing.\n",
        "We use the train_datagen object to load and preprocess the training images. Specifically, the flow_from_directory() function is used to read images directly from the directory and generate batches of data that will be fed into the model for training.\n"
      ],
      "metadata": {
        "id": "x_9YJDE8fVhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_rows, img_cols),   # Resize images to the size VGG16 expects\n",
        "    batch_size=batch_size,\n",
        "    seed = seed_value,\n",
        "    class_mode='binary',\n",
        "    shuffle=True # Binary classification: dent vs crack\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "2-mSUcO7fTzO",
        "outputId": "9c68df6f-7362-40f0-a3f7-f5d9bea80922"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'aircraft-damage-dataset-v1/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1972487355.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# Resize images to the size VGG16 expects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'aircraft-damage-dataset-v1/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iN_5K6kkfXBG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}